---
title: "case_study_week_6"
author: "Pankaj Kumar,  Brady Arendale , Kay Ayala"
date: "6/14/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(ggplot2)
require(reshape2)
library(rpart)
library(data.table)
library(rattle)
library(RColorBrewer)
library(data.tree)
library(h2o)
library(caret)

library(DiagrammeR)



```

## R Markdown Plot email variables 



```{r cars}

getwd()
setwd("/Users/pankaj/dev/git/smu/qtw/case_study3/Week_5_Materials_2")
load("data.Rda") 

length(emailDFrp)

library(tidyverse)

plot(colSums(is.na(emailDFrp)))
df1= emailDFrp

df1$id = seq(1, length(emailDFrp$isRe))


df1 %>% 
  ggplot(mapping = aes(x= isRe, fill = isSpam))+
  geom_bar()

df1 %>% 
  ggplot(mapping = aes(x=id,  y = ..density.. , color = isSpam))+
  geom_density( )


 

```

## Tree Model 


```{r pressure, echo=FALSE}
set.seed(2568)
n <- nrow(emailDFrp)
train <- sort(sample(1:n, floor(n/2)))

# Training data will be:

emailDFrp.train <- emailDFrp[train,]

# negate the indices to get the test data:
emailDFrp.test <- emailDFrp[-train,]


emailDFrp.rp1 <-rpart(isSpam ~ isRe+underscore ,                         # formula
                data = emailDFrp,                       # data frame
                subset = train,                       # indices of training set
                method = "class",                     # classification tree
                parms = list(split = "information"),  # use entropy/deviance
                maxsurrogate = 0,                     # since no missing values
                cp = 0,                               # no size penalty
                minsplit = 5,                         # Nodes of size 5 (or # more) can be split,
                minbucket = 2,                        # provided each sub-node
                # contains at least 2 obs.
)

pred.rpint1 <- predict(emailDFrp.rp1,
                       newdata = emailDFrp[-train,],
                       type = "class")


#
#  Classification table on the test data
#

cm = table(emailDFrp$isSpam[-train], pred.rpint1)

confusionMatrix(cm)


summary(emailDFrp.rp1)

plot(emailDFrp.rp1, 
     uniform=TRUE,
     compress=TRUE,
     margin = .2)
text(emailDFrp.rp1, 
     use.n=TRUE, 
     all = TRUE,
     fancy = TRUE)

fancyRpartPlot(emailDFrp.rp1, main="Decision Tree Graph With 2 variables ")
```


### Grid search for tree model 

```{r}

train.control <- trainControl(
  method = "repeatedcv",
  number = 10, ## 10-fold CV
  repeats = 3,## repeated three times
  # USE AUC
  summaryFunction = twoClassSummary, 
  classProbs = TRUE
)

tune.gridcart <- expand.grid(maxdepth = 2:15)

#tune.gridcart <- expand.grid(cp = seq(2,10))


system.time (rpartFit2 <- train(isSpam ~ . ,                         
                                data = emailDFrp,
                                method = "rpart2", 
                                tuneGrid =tune.gridcart,
                                trControl = train.control,
                                metric = "ROC", na.action = na.pass
))



rpartFit2 

plot(rpartFit2)


```


From above grid search it looks like ROC curve area increases with number of depth but the increase is not much after max depth 6. so that one we ll choose for our final model 



#### Tree Model with all variables 

``` {r}


emailDFrp.rp <-rpart(isSpam ~ . ,                         # formula
                     data = emailDFrp,                       # data frame
                     subset = train,                       # indices of training set
                     method = "class",                     # classification tree
                     parms = list(split = "information"),  # use entropy/deviance
                     maxsurrogate = 0,                     # since no missing values
                     cp = 0,                               # no size penalty
                     minsplit = 5,                         # Nodes of size 5 (or # morecan be split,
                     minbucket = 2,
                     # provided each sub-node
                     # contains at least 2 obs.
                     control=rpart.control(maxdepth=6)
)


#summary(emailDFrp.rp)

plot(emailDFrp.rp, 
     uniform=TRUE,
     compress=TRUE,
     margin = .2)
text(emailDFrp.rp, 
     use.n=TRUE, 
     all = TRUE,
     fancy = TRUE)

fancyRpartPlot(emailDFrp.rp, main="Decision Tree Graph")


```
 
#### Evaluation of Model :

confusion matrix for model based on all vars 

```{r}

pred.rpint <- predict(emailDFrp.rp,
                       newdata = emailDFrp[-train,],
                       type = "class")


#
#  Classification table on the test data
#

cm = table(emailDFrp$isSpam[-train], pred.rpint)

confusionMatrix(cm)

```

### Variables that are most important for the model we found with grid search 

```{r}

emailDFrp.rp$variable.importance

```


#### H2O function definitions 



```{r}
# split into train and validation


library(data.tree)

createDataTree <- function(h2oTree) {
  h2oTreeRoot = h2oTree@root_node
  dataTree = Node$new(h2oTreeRoot@split_feature)
  dataTree$type = 'split'
  addChildren(dataTree, h2oTreeRoot)
  return(dataTree)
}

addChildren <- function(dtree, node) {
  
  if(class(node)[1] != 'H2OSplitNode') return(TRUE)
  
  feature = node@split_feature
  id = node@id
  na_direction = node@na_direction
  
  if(is.na(node@threshold)) {
    leftEdgeLabel = printValues(node@left_levels, 
                                na_direction=='LEFT', 4)
    rightEdgeLabel = printValues(node@right_levels, 
                                 na_direction=='RIGHT', 4)
  }else {
    leftEdgeLabel = paste("<", node@threshold, 
                          ifelse(na_direction=='LEFT',',NA',''))
    rightEdgeLabel = paste(">=", node@threshold, 
                           ifelse(na_direction=='RIGHT',',NA',''))
  }
  
  left_node = node@left_child
  right_node = node@right_child
  
  if(class(left_node)[[1]] == 'H2OLeafNode')
    leftLabel = paste("prediction:", left_node@prediction)
  else
    leftLabel = left_node@split_feature
  
  if(class(right_node)[[1]] == 'H2OLeafNode')
    rightLabel = paste("prediction:", right_node@prediction)
  else
    rightLabel = right_node@split_feature
  
  if(leftLabel == rightLabel) {
    leftLabel = paste(leftLabel, "(L)")
    rightLabel = paste(rightLabel, "(R)")
  }
  
  dtreeLeft = dtree$AddChild(leftLabel)
  dtreeLeft$edgeLabel = leftEdgeLabel
  dtreeLeft$type = ifelse(class(left_node)[1] == 'H2OSplitNode', 'split', 'leaf')
  
  dtreeRight = dtree$AddChild(rightLabel)
  dtreeRight$edgeLabel = rightEdgeLabel
  dtreeRight$type = ifelse(class(right_node)[1] == 'H2OSplitNode', 'split', 'leaf')
  
  addChildren(dtreeLeft, left_node)
  addChildren(dtreeRight, right_node)
  
  return(FALSE)
}

printValues <- function(values, is_na_direction, n=4) {
  l = length(values)
  if(l == 0)
    value_string = ifelse(is_na_direction, "NA", "")
  else
    value_string = paste0(paste0(values[1:min(n,l)], collapse = ', '),
                          ifelse(l > n, ",...", ""),
                          ifelse(is_na_direction, ", NA", ""))
  return(value_string)
}

```


### H2O random forest model 



```{r}

# Build and train the model:

h2o.init()

emailDHex = as.h2o(emailDFrp)

splits = h2o.splitFrame(data = emailDHex, ratios = .8, seed = 1234)
trainHex = splits[[1]]
validHex = splits[[2]]
predictors = c("isRe")
predictors = names(emailDFrp)[c(seq(2,29))]
response = c("isSpam")


emailD_2tree <- h2o.randomForest(x = predictors,
                                  y = response,
                                  ntrees = 5,
                                  max_depth = 5,
                                  min_rows = 20,
                                  binomial_double_trees = TRUE,
                                  training_frame = trainHex,
                                  validation_frame = validHex)

emailDH2oTree2 = h2o.getModelTree(model = emailD_2tree, tree_number = 2)

library(data.tree)


library(DiagrammeR)

emailDataTree = createDataTree(emailDH2oTree2)

GetEdgeLabel <- function(node) {return (node$edgeLabel)}
GetNodeShape <- function(node) {switch(node$type, 
                                       split = "diamond", leaf = "oval")}
GetFontName <- function(node) {switch(node$type, 
                                      split = 'Palatino-bold', 
                                      leaf = 'Palatino')}
SetEdgeStyle(emailDataTree, fontname = 'Palatino-italic', 
             label = GetEdgeLabel, labelfloat = TRUE,
             fontsize = "26", fontcolor='royalblue4')
SetNodeStyle(emailDataTree, fontname = GetFontName, shape = GetNodeShape, 
             fontsize = "26", fontcolor='royalblue4',
             height="0.75", width="1")

SetGraphStyle(emailDataTree, rankdir = "TD", dpi=70.)

plot(emailDataTree, output = "graph")

emailDataTree

h2o.shutdown()


```

